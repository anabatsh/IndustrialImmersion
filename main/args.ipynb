{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for DiffDock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 12:18:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import fairseq.tasks:  /Users/anabatsh/Desktop/Industrial_Immersion/Transformer-M/fairseq/tasks\n",
      "import import_tasks with:  fairseq.tasks\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from fairseq import checkpoint_utils, utils, options, tasks\n",
    "# from fairseq.logging import progress_bar\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
    "# import ogb\n",
    "from pathlib import Path\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys\n",
    "from os import path\n",
    "import importlib\n",
    "\n",
    "sys.path.append(path.dirname(path.dirname(path.abspath('evaluate.py'))))\n",
    "\n",
    "# import logging\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hubert_pretraining': fairseq.tasks.hubert_pretraining.HubertPretrainingConfig,\n",
       " 'translation': fairseq.tasks.translation.TranslationConfig,\n",
       " 'translation_lev': fairseq.tasks.translation_lev.TranslationLevenshteinConfig,\n",
       " 'language_modeling': fairseq.tasks.language_modeling.LanguageModelingConfig,\n",
       " 'simul_text_to_text': fairseq.tasks.translation.TranslationConfig,\n",
       " 'audio_pretraining': fairseq.tasks.audio_pretraining.AudioPretrainingConfig,\n",
       " 'sentence_prediction': fairseq.tasks.sentence_prediction.SentencePredictionConfig,\n",
       " 'translation_from_pretrained_xlm': fairseq.tasks.translation_from_pretrained_xlm.TranslationFromPretrainedXLMConfig,\n",
       " 'audio_finetuning': fairseq.tasks.audio_finetuning.AudioFinetuningConfig,\n",
       " 'masked_lm': fairseq.tasks.masked_lm.MaskedLMConfig,\n",
       " 'dummy_lm': fairseq.benchmark.dummy_lm.DummyLMConfig,\n",
       " 'dummy_masked_lm': fairseq.benchmark.dummy_masked_lm.DummyMaskedLMConfig}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairseq.tasks import TASK_DATACLASS_REGISTRY, TASK_REGISTRY\n",
    "\n",
    "TASK_DATACLASS_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path to data\n",
    "# data_path = './datasets/pcq-pos'\n",
    "\n",
    "# # path to checkpoints, e.g., ./logs/L12\n",
    "# save_path = './logs/{folder_to_checkpoints}'    \n",
    "\n",
    "# # set layers=18 for 18-layer model\n",
    "# layers = 12\n",
    "\n",
    "# # dimension of hidden layers                                    \n",
    "# hidden_size = 768\n",
    "\n",
    "# # dimension of feed-forward layers\n",
    "# ffn_size = 768\n",
    "\n",
    "# # number of attention heads\n",
    "# num_head = 32\n",
    "\n",
    "# # number of Gaussian Basis kernels\n",
    "# num_3d_bias_kernel = 128\n",
    "\n",
    "# # batch size for a single gpu\n",
    "# batch_size = 256\n",
    "\n",
    "# dataset_name = \"PCQM4M-LSC-V2-3D\"\t\t\t\t   \n",
    "# add_3d = \"true\"\n",
    "\n",
    "# # ------------------------------\n",
    "# batch_size = 256\n",
    "# update_freq = 1\n",
    "# seed = 1\n",
    "# clip_norm = 5\n",
    "# # data_path = './datasets/'\n",
    "# # save_path = './logs/path_to_ckpts/'\n",
    "# dropout = 0.0\n",
    "# act_dropout = 0.1\n",
    "# attn_dropout = 0.1\n",
    "# weight_decay = 0.0\n",
    "# sandwich_ln = \"false\"\n",
    "# droppath_prob = 0.1\n",
    "# noise_scale = 0.2\n",
    "# mode_prob = \"0.2,0.2,0.6\"\n",
    "\n",
    "# dataset_name = \"PCQM4M-LSC-V2-3D\"\n",
    "# add_3d = \"true\"\n",
    "# no_2d = \"false\"\n",
    "\n",
    "# # ------------------------------\n",
    "# # python evaluate.py \n",
    "# # \t--user-dir $(realpath ./Transformer-M)\n",
    "# # \t--data-path $data_path \n",
    "# # \t--num-workers 16\n",
    "# # \t--ddp-backend=legacy_ddp \n",
    "# # \t--dataset-name $dataset_name \n",
    "# # \t--batch-size $batch_size \n",
    "# # \t--data-buffer-size 20\n",
    "# # \t--task graph_prediction \n",
    "# # \t--criterion graph_prediction \n",
    "# # \t--arch transformer_m_base --num-classes 1\n",
    "# # \t--encoder-layers $layers \n",
    "# # \t--encoder-attention-heads $num_head \n",
    "# # \t--add-3d \n",
    "# # \t--num-3d-bias-kernel $num_3d_bias_kernel\n",
    "# # \t--encoder-embed-dim $hidden_size \n",
    "# # \t--encoder-ffn-embed-dim $ffn_size \n",
    "# # \t--droppath-prob $droppath_prob\n",
    "# # \t--attention-dropout $attn_dropout \n",
    "# # \t--act-dropout $act_dropout \n",
    "# # \t--dropout $dropout\n",
    "# # \t--save-dir $save_path \n",
    "# # \t--noise-scale $noise_scale \n",
    "# # \t--mode-prob $mode_prob \n",
    "# # \t--split valid \n",
    "# # \t--metric mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    act_dropout=0.1, activation_fn='gelu', add_3d=True, add_prev_output_tokens=False, \n",
    "    all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, \n",
    "    amp_scale_window=None, apply_init=True, arch='transformer_m_base', attention_dropout=0.1, \n",
    "    azureml_logging=False, batch_size=256, batch_size_valid=256, best_checkpoint_metric='loss', \n",
    "    bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, \n",
    "    checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, \n",
    "    criterion='graph_prediction', curriculum=0, data_buffer_size=20, data_path='./datasets/pcq-pos', \n",
    "    dataset_impl=None, dataset_name='PCQM4M-LSC-V2-3D', ddp_backend='legacy_ddp', ddp_comm_hook='none', \n",
    "    device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, \n",
    "    distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, \n",
    "    distributed_world_size=1, dropout=0.0, droppath_prob=0.1, edge_type='multi_hop', ema_decay=0.9999, \n",
    "    ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, \n",
    "    encoder_attention_heads=32, encoder_embed_dim=768, encoder_ffn_embed_dim=768, encoder_layers=12, \n",
    "    encoder_learned_pos=True, encoder_normalize_before=True, eos=2, fast_stat_sync=False, \n",
    "    find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, \n",
    "    fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, \n",
    "    fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, \n",
    "    fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, \n",
    "    grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, \n",
    "    init_token=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, \n",
    "    keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, \n",
    "    log_format=None, log_interval=100, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, \n",
    "    max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, \n",
    "    maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, \n",
    "    metric='mae', min_loss_scale=0.0001, mode_prob='0.2,0.2,0.6', model_parallel_size=1, multi_hop_max_dist=5, \n",
    "    no_2d=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, \n",
    "    no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, \n",
    "    no_shuffle=False, no_token_positional_embeddings=False, noise_scale=0.2, not_fsdp_flatten_parameters=False, \n",
    "    nprocs_per_node=1, num_3d_bias_kernel=128, num_atoms=4608, num_classes=1, num_edge_dis=128, num_edges=1536, \n",
    "    num_in_degree=512, num_out_degree=512, num_segment=2, num_shards=1, num_spatial=512, num_workers=16, \n",
    "    on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, patience=-1, \n",
    "    pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, \n",
    "    pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, \n",
    "    pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', \n",
    "    pooler_activation_fn='tanh', profile=False, quantization_config_path=None, required_batch_size_multiple=8, \n",
    "    required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, \n",
    "    reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sandwich_ln=False, \n",
    "    save_dir='./logs/L12', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sent_loss=False, \n",
    "    sentence_avg=False, sentence_class_num=2, separator_token=None, shard_id=0, \n",
    "    share_encoder_input_output_embed=False, shorten_data_split_list='', shorten_method='none', \n",
    "    simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', \n",
    "    slowmo_momentum=None, split='valid', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, \n",
    "    suppress_crashes=False, task='graph_prediction', tensorboard_logdir=None, threshold_loss_scale=None, \n",
    "    tokenizer=None, tpu=False, train_subset='train', unk=3, update_epoch_batch_itr=False, update_freq=[1], \n",
    "    update_ordered_indices_seed=False, use_bmuf=False, use_plasma_view=False, use_sharded_state=False, \n",
    "    user_dir='/Users/anabatsh/Desktop/Industrial_Immersion/Transformer-M/Transformer-M', valid_subset='valid', \n",
    "    validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, \n",
    "    warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_(args, use_pretrained, checkpoint_path=None, logger=None):\n",
    "    \n",
    "    module_path = getattr(args, \"user_dir\", None)\n",
    "    module_parent, module_name = os.path.split(module_path)\n",
    "    importlib.import_module(module_name)\n",
    "\n",
    "    tasks_path = os.path.join(module_path, \"tasks\")\n",
    "    if os.path.exists(tasks_path):\n",
    "        from fairseq.tasks import import_tasks\n",
    "        import_tasks(tasks_path, f\"{module_name}.tasks\")\n",
    "        models_path = os.path.join(module_path, \"models\")\n",
    "        print('models_path', models_path, os.path.exists(models_path))\n",
    "        if os.path.exists(models_path):\n",
    "            from fairseq.models import import_models\n",
    "            import_models(models_path, f\"{module_name}.models\")\n",
    "\n",
    "    cfg = convert_namespace_to_omegaconf(args)\n",
    "    np.random.seed(cfg.common.seed)\n",
    "    utils.set_torch_seed(cfg.common.seed)\n",
    "\n",
    "    # initialize task\n",
    "    task = tasks.setup_task(cfg.task)\n",
    "    return\n",
    "    # model = task.build_model(cfg.model)\n",
    "\n",
    "    # # load checkpoint\n",
    "\n",
    "    # model_state = torch.load(checkpoint_path)[\"model\"]\n",
    "    # model.load_state_dict(\n",
    "    #     model_state, strict=True, model_cfg=cfg.model\n",
    "    # )\n",
    "    # del model_state\n",
    "\n",
    "    # model.to(torch.cuda.current_device())\n",
    "    # # load dataset\n",
    "    # split = args.split\n",
    "    # task.load_dataset(split)\n",
    "    # batch_iterator = task.get_batch_iterator(\n",
    "    #     dataset=task.dataset(split),\n",
    "    #     max_tokens=cfg.dataset.max_tokens_valid,\n",
    "    #     max_sentences=cfg.dataset.batch_size_valid,\n",
    "    #     max_positions=utils.resolve_max_positions(\n",
    "    #         task.max_positions(),\n",
    "    #         model.max_positions(),\n",
    "    #     ),\n",
    "    #     ignore_invalid_inputs=cfg.dataset.skip_invalid_size_inputs_valid_test,\n",
    "    #     required_batch_size_multiple=cfg.dataset.required_batch_size_multiple,\n",
    "    #     seed=cfg.common.seed,\n",
    "    #     num_workers=cfg.dataset.num_workers,\n",
    "    #     epoch=0,\n",
    "    #     data_buffer_size=cfg.dataset.data_buffer_size,\n",
    "    #     disable_iterator_cache=False,\n",
    "    # )\n",
    "    # itr = batch_iterator.next_epoch_itr(\n",
    "    #     shuffle=False, set_dataset_epoch=False\n",
    "    # )\n",
    "    # progress = progress_bar.progress_bar(\n",
    "    #     itr,\n",
    "    #     log_format=cfg.common.log_format,\n",
    "    #     log_interval=cfg.common.log_interval,\n",
    "    #     default_log_format=(\"tqdm\" if not cfg.common.no_progress_bar else \"simple\")\n",
    "    # )\n",
    "\n",
    "    # # infer\n",
    "    # y_pred = []\n",
    "    # y_true = []\n",
    "    # with torch.no_grad():\n",
    "    #     model.eval()\n",
    "    #     for i, sample in enumerate(progress):\n",
    "    #         sample = utils.move_to_cuda(sample)\n",
    "    #         y = model(**sample[\"net_input\"])[0][:, 0, :].reshape(-1)\n",
    "    #         y_pred.extend(y.detach().cpu())\n",
    "    #         y_true.extend(sample[\"target\"].detach().cpu().reshape(-1)[:y.shape[0]])\n",
    "    #         torch.cuda.empty_cache()\n",
    "\n",
    "    # # save predictions\n",
    "    # y_pred = torch.Tensor(y_pred)\n",
    "    # y_true = torch.Tensor(y_true)\n",
    "\n",
    "    # # evaluate pretrained models\n",
    "\n",
    "    # if args.metric == \"auc\":\n",
    "    #     auc = roc_auc_score(y_true, y_pred)\n",
    "    #     logger.info(f\"auc: {auc}\")\n",
    "    #     return auc\n",
    "    # elif args.metric == \"mae\":\n",
    "    #     mae = np.mean(np.abs(y_true.numpy() - y_pred.numpy()))\n",
    "    #     logger.info(f\"mae: {mae}\")\n",
    "    #     return mae\n",
    "    # else:\n",
    "    #     raise ValueError(f\"Unsupported metric {args.metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 12:18:12 | INFO | rdkit | Enabling RDKit 2023.03.1 jupyter extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import import_tasks with:  Transformer-M.tasks\n",
      "models_path /Users/anabatsh/Desktop/Industrial_Immersion/Transformer-M/Transformer-M/models True\n",
      "{'hubert_pretraining': <class 'fairseq.tasks.hubert_pretraining.HubertPretrainingConfig'>, 'translation': <class 'fairseq.tasks.translation.TranslationConfig'>, 'translation_lev': <class 'fairseq.tasks.translation_lev.TranslationLevenshteinConfig'>, 'language_modeling': <class 'fairseq.tasks.language_modeling.LanguageModelingConfig'>, 'simul_text_to_text': <class 'fairseq.tasks.translation.TranslationConfig'>, 'audio_pretraining': <class 'fairseq.tasks.audio_pretraining.AudioPretrainingConfig'>, 'sentence_prediction': <class 'fairseq.tasks.sentence_prediction.SentencePredictionConfig'>, 'translation_from_pretrained_xlm': <class 'fairseq.tasks.translation_from_pretrained_xlm.TranslationFromPretrainedXLMConfig'>, 'audio_finetuning': <class 'fairseq.tasks.audio_finetuning.AudioFinetuningConfig'>, 'masked_lm': <class 'fairseq.tasks.masked_lm.MaskedLMConfig'>, 'dummy_lm': <class 'fairseq.benchmark.dummy_lm.DummyLMConfig'>, 'dummy_masked_lm': <class 'fairseq.benchmark.dummy_masked_lm.DummyMaskedLMConfig'>, 'graph_prediction': <class 'Transformer-M.tasks.graph_prediction.GraphPredictionConfig'>, 'graph_prediction_qm9': <class 'Transformer-M.tasks.graph_prediction.GraphPredictionConfigQM9'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anabatsh/miniforge3/envs/indimm/lib/python3.8/site-packages/hydra/experimental/initialize.py:35: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(\n",
      "/Users/anabatsh/miniforge3/envs/indimm/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "/Users/anabatsh/miniforge3/envs/indimm/lib/python3.8/site-packages/hydra/core/default_element.py:122: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/Users/anabatsh/miniforge3/envs/indimm/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3505: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/anabatsh/miniforge3/envs/indimm/lib/python3.8/site-packages/hydra/compose.py:49: UserWarning: \n",
      "The strict flag in the compose API is deprecated and will be removed in the next version of Hydra.\n",
      "See https://hydra.cc/docs/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK <class 'Transformer-M.tasks.graph_prediction.GraphPredictionTask'>\n",
      "Converting SMILES strings into graphs...\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "# parser = options.get_training_parser()\n",
    "\n",
    "# parser.add_argument(\n",
    "#     \"--split\",\n",
    "#     type=str,\n",
    "# )\n",
    "# parser.add_argument(\n",
    "#     \"--metric\",\n",
    "#     type=str,\n",
    "# )\n",
    "# args = options.parse_args_and_arch(parser, modify_parser=None)\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "for checkpoint_fname in os.listdir(args.save_dir):\n",
    "    checkpoint_path = Path(args.save_dir) / checkpoint_fname\n",
    "    if str(checkpoint_path)[-3:] == '.pt':\n",
    "        # logger.info(f\"evaluating checkpoint file {checkpoint_path}\")\n",
    "        result = eval_(args, False, checkpoint_path, None) #logger)\n",
    "        open(str(checkpoint_path)[:-3] + f'_{args.split}_{result:.5f}.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {\n",
    "#     '_name': None, \n",
    "#     'common': {\n",
    "#         '_name': None, 'no_progress_bar': False, 'log_interval': 100, \n",
    "#         'log_format': None, 'log_file': None, 'tensorboard_logdir': None, \n",
    "#         'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, \n",
    "#         'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, \n",
    "#         'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, \n",
    "#         'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, \n",
    "#         'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, \n",
    "#         'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, \n",
    "#         'user_dir': '/Users/anabatsh/Desktop/Industrial_Immersion/Transformer-M/Transformer-M', 'empty_cache_freq': 0, \n",
    "#         'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, \n",
    "#         'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, \n",
    "#         'plasma_path': '/tmp/plasma'\n",
    "#     }, \n",
    "#     'common_eval': {\n",
    "#         '_name': None, 'path': None, 'post_process': None, \n",
    "#         'quiet': False, 'model_overrides': '{}', 'results_path': None\n",
    "#     }, \n",
    "#     'distributed_training': {\n",
    "#         '_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, \n",
    "#         'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, \n",
    "#         'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, \n",
    "#         'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, \n",
    "#         'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, \n",
    "#         'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, \n",
    "#         'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, \n",
    "#         'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, \n",
    "#         'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, \n",
    "#         'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', \n",
    "#         'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, \n",
    "#         'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, \n",
    "#         'use_sharded_state': False, 'not_fsdp_flatten_parameters': False\n",
    "#     }, \n",
    "#     'dataset': {\n",
    "#         '_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': False,\n",
    "#           'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, \n",
    "#           'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 20,\n",
    "#             'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, \n",
    "#             'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, \n",
    "#             'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, \n",
    "#             'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, \n",
    "#             'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, \n",
    "#             'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False\n",
    "#     }, \n",
    "#     'optimization': {\n",
    "#         '_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, \n",
    "#         'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], \n",
    "#         'stop_min_lr': -1.0, 'use_bmuf': False\n",
    "#     }, \n",
    "#     'checkpoint': {\n",
    "#         '_name': None, 'save_dir': './logs/L12', 'restore_file': 'checkpoint_last.pt', \n",
    "#         'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, \n",
    "#         'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', \n",
    "#         'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, \n",
    "#         'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, \n",
    "#         'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, \n",
    "#         'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', \n",
    "#         'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', \n",
    "#         'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, \n",
    "#         'write_checkpoints_asynchronously': False, 'model_parallel_size': 1\n",
    "#     }, \n",
    "#     'bmuf': {\n",
    "#         '_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, \n",
    "#         'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1\n",
    "#     }, \n",
    "#     'generation': {\n",
    "#         '_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, \n",
    "#         'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, \n",
    "#         'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, \n",
    "#         'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, \n",
    "#         'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, \n",
    "#         'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, \n",
    "#         'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, \n",
    "#         'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, \n",
    "#         'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, \n",
    "#         'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False\n",
    "#     }, \n",
    "#     'eval_lm': {\n",
    "#         '_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, \n",
    "#         'softmax_batch': 9223372036854775807\n",
    "#     }, \n",
    "#     'interactive': {\n",
    "#         '_name': None, 'buffer_size': 0, 'input': '-'\n",
    "#     }, \n",
    "#     'model': Namespace(\n",
    "#         _name='transformer_m_base', act_dropout=0.1, activation_fn='gelu', \n",
    "#         add_3d=True, add_prev_output_tokens=False, all_gather_list_size=16384, \n",
    "#         amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, \n",
    "#         apply_init=True, arch='transformer_m_base', attention_dropout=0.1, azureml_logging=False, \n",
    "#         batch_size=256, batch_size_valid=256, best_checkpoint_metric='loss', bf16=False, bpe=None, \n",
    "#         broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', \n",
    "#         clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, \n",
    "#         criterion='graph_prediction', curriculum=0, data_buffer_size=20, data_path='./datasets/pcq-pos', \n",
    "#         dataset_impl=None, dataset_name='PCQM4M-LSC-V2-3D', ddp_backend='legacy_ddp', \n",
    "#         ddp_comm_hook='none', device_id=0, disable_validation=False, distributed_backend='nccl', \n",
    "#         distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1,\n",
    "#         distributed_rank=0, distributed_world_size=1, dropout=0.0, droppath_prob=0.1, edge_type='multi_hop', \n",
    "#         ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, \n",
    "#         empty_cache_freq=0, encoder_attention_heads=32, encoder_embed_dim=768, encoder_ffn_embed_dim=768, \n",
    "#         encoder_layers=12, encoder_learned_pos=True, encoder_normalize_before=True, eos=2, fast_stat_sync=False, \n",
    "#         find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, \n",
    "#         fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, \n",
    "#         fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, \n",
    "#         gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1,\n",
    "#         ignore_unused_valid_subsets=False, init_token=None, keep_best_checkpoints=-1, keep_interval_updates=-1, \n",
    "#         keep_interval_updates_pattern=-1, keep_last_epochs=-1, load_checkpoint_on_all_dp_ranks=False, \n",
    "#         localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.25], \n",
    "#         lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_tokens=None, max_tokens_valid=None, \n",
    "#         max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, \n",
    "#         memory_efficient_bf16=False, memory_efficient_fp16=False, metric='mae', min_loss_scale=0.0001, \n",
    "#         mode_prob='0.2,0.2,0.6', model_parallel_size=1, multi_hop_max_dist=5, no_2d=False, \n",
    "#         no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, \n",
    "#         no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, \n",
    "#         no_seed_provided=False, no_shuffle=False, no_token_positional_embeddings=False, \n",
    "#         noise_scale=0.2, not_fsdp_flatten_parameters=False, nprocs_per_node=1, \n",
    "#         num_3d_bias_kernel=128, num_atoms=4608, num_classes=1, num_edge_dis=128, \n",
    "#         num_edges=1536, num_in_degree=512, num_out_degree=512, num_segment=2, num_shards=1, \n",
    "#         num_spatial=512, num_workers=16, on_cpu_convert_precision=False, optimizer=None, \n",
    "#         optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', \n",
    "#         pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, \n",
    "#         pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, \n",
    "#         pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', \n",
    "#         profile=False, quantization_config_path=None, required_batch_size_multiple=8, \n",
    "#         required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, \n",
    "#         reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, \n",
    "#         restore_file='checkpoint_last.pt', sandwich_ln=False, save_dir='./logs/L12', \n",
    "#         save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sent_loss=False, \n",
    "#         sentence_avg=False, sentence_class_num=2, separator_token=None, shard_id=0, \n",
    "#         share_encoder_input_output_embed=False, shorten_data_split_list='', shorten_method='none', \n",
    "#         simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', \n",
    "#         slowmo_momentum=None, split='valid', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, \n",
    "#         suppress_crashes=False, task='graph_prediction', tensorboard_logdir=None, threshold_loss_scale=None, \n",
    "#         tokenizer=None, tpu=False, train_subset='train', unk=3, update_epoch_batch_itr=False, update_freq=[1], \n",
    "#         update_ordered_indices_seed=False, use_bmuf=False, use_plasma_view=False, use_sharded_state=False, \n",
    "#         user_dir='/Users/anabatsh/Desktop/Industrial_Immersion/Transformer-M/Transformer-M', \n",
    "#         valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, \n",
    "#         wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'\n",
    "#     ), \n",
    "#     'task': {\n",
    "#         '_name': 'graph_prediction', 'data_path': './datasets/pcq-pos', \n",
    "#         'noise_scale': 0.2, 'sandwich_ln': False, 'num_classes': 1, 'init_token': None, \n",
    "#         'separator_token': None, 'no_shuffle': False, 'shorten_method': 'none', \n",
    "#         'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, \n",
    "#         'dataset_name': 'PCQM4M-LSC-V2-3D', 'num_atoms': 4608, 'num_edges': 1536, \n",
    "#         'num_in_degree': 512, 'num_out_degree': 512, 'num_spatial': 512, 'num_edge_dis': 128, \n",
    "#         'multi_hop_max_dist': 5, 'edge_type': 'multi_hop', 'regression_target': True, 'seed': 1\n",
    "#     }, \n",
    "#     'criterion': {\n",
    "#         '_name': 'graph_prediction', 'tpu': False\n",
    "#     }, \n",
    "#     'optimizer': None, \n",
    "#     'lr_scheduler': {\n",
    "#         '_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, \n",
    "#         'warmup_updates': 0, 'lr': [0.25]\n",
    "#     }, \n",
    "#     'scoring': {\n",
    "#         '_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3\n",
    "#     }, \n",
    "#     'bpe': None, \n",
    "#     'tokenizer': None, \n",
    "#     'ema': {\n",
    "#         '_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, \n",
    "#         'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False\n",
    "#     }, \n",
    "#     'simul_type': None\n",
    "# }\n",
    "# TASK <class 'Transformer-M.tasks.graph_prediction.GraphPredictionTask'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indimm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
